{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_10 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class NoneReduce():\n",
    "    def __init__(self, loss_func): \n",
    "        self.loss_func,self.old_red = loss_func,None\n",
    "        \n",
    "    def __enter__(self):\n",
    "        if hasattr(self.loss_func, 'reduction'):\n",
    "            self.old_red = getattr(self.loss_func, 'reduction')\n",
    "            setattr(self.loss_func, 'reduction', 'none')\n",
    "            return self.loss_func\n",
    "        else: return partial(self.loss_func, reduction='none')\n",
    "        \n",
    "    def __exit__(self, type, value, traceback):\n",
    "        if self.old_red is not None: setattr(self.loss_func, 'reduction', self.old_red)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from torch.distributions.beta import Beta\n",
    "\n",
    "def unsqueeze(input, dims):\n",
    "    for dim in listify(dims): input = torch.unsqueeze(input, dim)\n",
    "    return input\n",
    "\n",
    "def reduce_loss(loss, reduction='mean'):\n",
    "    return loss.mean() if reduction=='mean' else loss.sum() if reduction=='sum' else loss    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class MixUp(Callback):\n",
    "    _order = 90 #Runs after normalization and cuda\n",
    "    def __init__(self, α:float=0.4): self.distrib = Beta(tensor([α]), tensor([α]))\n",
    "    \n",
    "    def begin_fit(self): self.old_loss_func,self.run.loss_func = self.run.loss_func,self.loss_func\n",
    "    \n",
    "    def begin_batch(self):\n",
    "        if not self.in_train: return #Only mixup things during training\n",
    "        λ = self.distrib.sample((self.yb.size(0),)).squeeze().to(self.xb.device)\n",
    "        λ = torch.stack([λ, 1-λ], 1)\n",
    "        self.λ = unsqueeze(λ.max(1)[0], (1,2,3))\n",
    "        shuffle = torch.randperm(self.yb.size(0)).to(self.xb.device)\n",
    "        xb1,self.yb1 = self.xb[shuffle],self.yb[shuffle]\n",
    "        self.run.xb = lin_comb(self.xb, xb1, self.λ)\n",
    "        \n",
    "    def after_fit(self): self.run.loss_func = self.old_loss_func\n",
    "    \n",
    "    def loss_func(self, pred, yb):\n",
    "        if not self.in_train: return self.old_loss_func(pred, yb)\n",
    "        with NoneReduce(self.old_loss_func) as loss_func:\n",
    "            loss1 = loss_func(pred, yb)\n",
    "            loss2 = loss_func(pred, self.yb1)\n",
    "        loss = lin_comb(loss1, loss2, self.λ)\n",
    "        return reduce_loss(loss, getattr(self.old_loss_func, 'reduction', 'mean'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class LabelSmoothingCrossEntropy(nn.Module):\n",
    "    def __init__(self, ε:float=0.1, reduction='mean'):\n",
    "        super().__init__()\n",
    "        self.ε,self.reduction = ε,reduction\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        c = output.size()[-1]\n",
    "        log_preds = F.log_softmax(output, dim=-1)\n",
    "        loss = reduce_loss(-log_preds.sum(dim=-1), self.reduction)\n",
    "        nll = F.nll_loss(log_preds, target, reduction=self.reduction)\n",
    "        return lin_comb(loss/c, nll, self.ε)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 10b_mixup_label_smoothing.ipynb to exp/nb_10b.py\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 10b_mixup_label_smoothing.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
